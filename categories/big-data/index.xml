<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>big-data on mtunique blog</title><link>https://mtunique.com/categories/big-data/</link><description>Recent content in big-data on mtunique blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>mtunique</copyright><lastBuildDate>Sun, 26 Mar 2017 22:30:27 +0800</lastBuildDate><atom:link href="https://mtunique.com/categories/big-data/index.xml" rel="self" type="application/rss+xml"/><item><title>Flink Table/SQL API 规划 —— Dynamic Table</title><link>https://mtunique.com/posts/flink_sql_outlook/</link><pubDate>Sun, 26 Mar 2017 22:30:27 +0800</pubDate><guid>https://mtunique.com/posts/flink_sql_outlook/</guid><description>动态表的概念是社区很早就提出的但并没有全部实现下文中所有介绍都是基于已有规划和proposal给出的，可能与之后实现存在出入仅供参考 概念 动态表直观上看是一个类似于数据库中的Materialized View概念。动态表随着时间改变；类似静态的batch table一样可以用标准SQL进行查询然后一个新的动态表；可以和流无损地互相转换(对偶的)。对现有的API最大的改进关键在表的内容随着时间改变，而现在的状态只是append。当前的streaming table可以认为是一种动态表，append模式的动态表。
流到 Dynamic Table 流被转换成Table时决定选择哪种模式是依据表的schema是否定义primary key。
Append模式： 如果表的schema没有包括key的定义那转换成表时采用append模式。把流中每条新来的record当做新的row append到表中。一旦数据加到表中就不能再被更新和删除(指当前表中，不考虑转换成新表)。
Replace模式： 相对应，如果定义了key，那么对于流中的每条记录如果key不在表中就insert否则就update。
Dynamic Table 到 流 表到流的操作是把表的所有change以changelog stream的方式发送到下游。这一步也有两种模式。
Retraction模式： traction模式中对于Dynamic Table的insert和delete的change分别产生insert或delete event。如果是update的change会产生两种change event，对于之前发送出去的同样key的record会产生delete event，对于当前的record是产生insert event。如下图所示：
Update模式： update模式依赖Dynamic Table定义了key。所有的change event是一个kv对。key对应表的key在当前record中的值；对于insert和change value对应新的record。对于delete value是空表示该可以已经被删除。如下图所示：
example 表的内容随着时间改变意味着对表的query结果也是随着时间改变的。我们定义：
A[t]: 时间t时的表A q(A[t])：时间t时对表A执行query q 举个例子来理解动态表的概念：
query的限制 由于流是无限的，相对应 Dynamic Table 也是无界的。当查询无限的表的时候我们需要保证query的定时是良好的，有意义可行的。
1.在实践中Flink将查询转换成持续的流式应用，执行的query仅针对当前的逻辑时间，所以不支持对于任意时间点的查询(A[t])。 2.最直观的原则是query可能的状态和计算必须是有界的，所以可以支持可增量计算的查询：
不断更新当前结果的查询：查询可以产生insert，update和delete更改。查询可以表示为 Q(t+1) = q'(Q(t), c(T, t, t+1))，其中Q(t)是query q的前一次查询结果，c(T, t, t_+1) 是表T从t+1到t的变化, q&amp;rsquo;是q的增量版本。 产生append-only的表，可以从输入表的尾端直接计算出新数据。查询可以表示为 Q(t+1) = q''(c(T, t-x, t+1)) ∪ Q(t)，q'&amp;lsquo;是不需要时间t时q的结果增量版本query q。c(T, t-x, t+1)是表T尾部的x+1个数据，x取决于语义。例如最后一小时的window aggregation至少需要最后一小时的数据作为状态。其他能支持的查询类型还有：单独在每一行上操作的SELECT WHERE；rowtime上的GROUP BY子句（比如基于时间的window aggregate）；ORDER BY rowtime的OVER windows(row-windows)；ORDER BY rowtime。 3.</description></item><item><title>浅析 Flink Table/SQL API</title><link>https://mtunique.com/posts/flink_sql/</link><pubDate>Tue, 21 Mar 2017 22:30:27 +0800</pubDate><guid>https://mtunique.com/posts/flink_sql/</guid><description>从何而来 关系型API有很多好处：是声明式的，用户只需要告诉需要什么，系统决定如何计算；用户不必特地实现；更方便优化，可以执行得更高效。本身Flink就是一个统一批和流的分布式计算平台，所以社区设计关系型API的目的之一是可以让关系型API作为统一的一层，两种查询拥有同样的语义和语法。大多数流处理框架的API都是比较low-level的API，学习成本高而且很多逻辑需要写到UDF中，所以Apache Flink 添加了SQL-like的API处理关系型数据&amp;ndash;Table API。这套API中最重要的概念是Table(可以在上面进行关系型操作的结构化的DataSet或DataStream)。Table API 与 DataSet和DataStream API 结合紧密，DataSet 和 DataStream都可以很容易地转换成 Table，同样转换回来也很方便：
val execEnv = ExecutionEnvironment.getExecutionEnvironment val tableEnv = TableEnvironment.getTableEnvironment(execEnv) // obtain a DataSet from somewhere val tempData: DataSet[(String, Long, Double)] = // convert the DataSet to a Table val tempTable: Table = tempData.toTable(tableEnv, &amp;#39;location, &amp;#39;time, &amp;#39;tempF) // compute your result val avgTempCTable: Table = tempTable .where(&amp;#39;location.like(&amp;#34;room%&amp;#34;)) .select( (&amp;#39;time / (3600 * 24)) as &amp;#39;day, &amp;#39;Location as &amp;#39;room, ((&amp;#39;tempF - 32) * 0.</description></item><item><title>【未完成】spark和flink的内存管理简单介绍和对比</title><link>https://mtunique.com/posts/spark_flink_mem/</link><pubDate>Sat, 24 Dec 2016 11:30:27 +0800</pubDate><guid>https://mtunique.com/posts/spark_flink_mem/</guid><description>为什么要做内存管理 最近几年存储和网络硬件的升级对大数据领域相关的系统性能提升很大，在很多场景中CPU和内存的渐渐成为瓶颈。 然而大数据领域很多开源框架都使用JVM。相对 c/c++ JVM系语言对于CPU和内存的利用还是差很多的，主要体现在:
GC的开销较大，Full GC更会极大影响性能，尤其是对于为了处理更大数据开辟了极大内存空间的JVM来说。 Java对象的存储密度低。一个对象头就8字节，为了对齐有的时候还要补齐。Java对象的内存很难利用CPU的各级cache，对于 avx simd 等技术很难利用起来难以发挥CPU的这些优势。 OOM的问题影响稳定性。在大数据领域经常会遇到OOM的问题，除了影响稳定性之外，JVM崩溃后重新拉起的代价也很高。 为了解决这些问题spark flink hbase hive 等各大框架都在自己管理内存。框架自己比JVM更了解自己的内存，更熟悉生命周期，拥有更多的信息来管理内存。
// 直接的意思是&amp;quot;绕过&amp;quot;JVM的内存管理机制自己管理每一个字节，就像写C一样，而不是new出来等着GC；另一方面是指通过定制的序列化工具等技术直接操作数据内容不必全部反序列化或不反序列化。
统一管理内存 内存中的Java对象越少, GC压力越小，而且可以保证统一管理的内存一直呆在老年代，而且也可以是堆外内存。
Spark 和 Flink 都支持堆内和堆外两种内存的管理。管理的策略都和操作系统类似，对内存进行分段分页。两者都是一级页表。
Spark：页表的大小是 1 &amp;lt;&amp;lt; 13, 每个页(MemoryBlock)的大小不确定。on-heap模式时候能表示的最大页大小受限于long[]数组的最大长度，理论上最大能表示8192*2^32*****8字节(35T)。on-heap模式时如果页超过1M会触发bufferPools来复用long数组(HeapMemoryAllocator)。TaskMemoryManager接管Task的内存分配释放，&amp;ldquo;寻址&amp;rdquo;，分配的内存页大小不固定，具体执行内存申请是由HeapMemoryAllocator和UnsafeMemoryAllocator进行。
Flink: MemoryManager接管内存分配和释放，构造时页的大小固定，页表大小根据需要的内存反推。TaskManagerServices构造MemoryManager时会将页大小定为networkBufferSize, 默认大小为32KB, 为了配合flink的Network Buffer管理。AbstractPagedInputView, AbstractPagedOutputView以及各种InputView OutputView 用来进行跨page读写内存。
这些缓解了GC耗时和抖动问题。
spill到内存外持久化存储 具体原理和为什么都不叫显然，两者实现也没有什么差别。
Flink: 由内存使用者管理spill规则，并不像操作系统一样。比如: MutableHashTable，SpillingBuffer&amp;hellip; Spark: 同样由各类使用者各自管理，所有内存的消费者都继承MemoryConsumer abstract class， 实现具体spill方法。相对Flink更整洁，统一。BytesToBytesMap，ExternalAppendOnlyMap，ExternalSorter会spill到disk。 列方式存储 根据空间局部性原理，做到缓存友好首先对数据进行向量化存储。通常我们都是对结构化数据的一&amp;quot;列&amp;quot;进行相同的处理，所以
缓存友好算法 codegen (SIMD AVX)</description></item><item><title>如何选择三种Spark API</title><link>https://mtunique.com/posts/spark_api/</link><pubDate>Fri, 11 Nov 2016 14:30:27 +0800</pubDate><guid>https://mtunique.com/posts/spark_api/</guid><description>在这里查看 Apache Spark 2.0 Api 的改进：RDD，DataFrame，DataSet和SQL
Apache Spark 正在快速发展，包括更改和添加核心API。最具破坏性的改变之一是dataset。 Spark 1.0 使用RDD API，但是在最近的十二个月引入了两个新不兼容的API。Spark 1.3 引入了完全不同的DataFrame API 而且最近发布的 Spark 1.6 引入了 Dataset API 浏览版。
很多现有的 Spark 开发者想知道是否应该从 RDDs 直接切换到 Dataset API，或者先切换到 DataFrame API。Spark 新手应该选择哪个 API 开始学习。
这篇文章将提供每个API的概述，并且总结了每个的优缺点。 配套的github repo提供了例子，可以从这开始实验文中提到的方法。yd
RDD (弹性分布式数据集) API 从 1.0 开始一直存在 Spark 中。 这个接口和 Java 版本 JavaRDD 对于已经完成标准Spark教程的任何开发人员来说都是熟悉的。从开发人员的角度来看，RDD只是一组表示数据的Java或Scala对象。
RDD API 提供很多转换方法来在数据上执行计算，比如 map() ， filter() ，和 reduce() 。这些方法的结果表示转换后的新RDD。 然而，这些方法只是定义要执行的操作，直到调用action方法才执行转换。action 方法比如是： collect() 和 saveAsObjectFile().
RDD 转换和action例子 Scala: rdd.</description></item></channel></rss>