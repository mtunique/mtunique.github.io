<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>spark on mtunique blog</title><link>https://example.com/categories/spark/</link><description>Recent content in spark on mtunique blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>mtunique</copyright><lastBuildDate>Sat, 24 Dec 2016 11:30:27 +0800</lastBuildDate><atom:link href="https://example.com/categories/spark/index.xml" rel="self" type="application/rss+xml"/><item><title>【未完成】spark和flink的内存管理简单介绍和对比</title><link>https://example.com/posts/spark_flink_mem/</link><pubDate>Sat, 24 Dec 2016 11:30:27 +0800</pubDate><guid>https://example.com/posts/spark_flink_mem/</guid><description>为什么要做内存管理 最近几年存储和网络硬件的升级对大数据领域相关的系统性能提升很大，在很多场景中CPU和内存的渐渐成为瓶颈。 然而大数据领域很多开源框架都使用JVM。相对 c/c++ JVM系语言对于CPU和内存的利用还是差很多的，主要体现在:
GC的开销较大，Full GC更会极大影响性能，尤其是对于为了处理更大数据开辟了极大内存空间的JVM来说。 Java对象的存储密度低。一个对象头就8字节，为了对齐有的时候还要补齐。Java对象的内存很难利用CPU的各级cache，对于 avx simd 等技术很难利用起来难以发挥CPU的这些优势。 OOM的问题影响稳定性。在大数据领域经常会遇到OOM的问题，除了影响稳定性之外，JVM崩溃后重新拉起的代价也很高。 为了解决这些问题spark flink hbase hive 等各大框架都在自己管理内存。框架自己比JVM更了解自己的内存，更熟悉生命周期，拥有更多的信息来管理内存。
// 直接的意思是&amp;quot;绕过&amp;quot;JVM的内存管理机制自己管理每一个字节，就像写C一样，而不是new出来等着GC；另一方面是指通过定制的序列化工具等技术直接操作数据内容不必全部反序列化或不反序列化。
统一管理内存 内存中的Java对象越少, GC压力越小，而且可以保证统一管理的内存一直呆在老年代，而且也可以是堆外内存。
Spark 和 Flink 都支持堆内和堆外两种内存的管理。管理的策略都和操作系统类似，对内存进行分段分页。两者都是一级页表。
Spark：页表的大小是 1 &amp;lt;&amp;lt; 13, 每个页(MemoryBlock)的大小不确定。on-heap模式时候能表示的最大页大小受限于long[]数组的最大长度，理论上最大能表示8192*2^32*****8字节(35T)。on-heap模式时如果页超过1M会触发bufferPools来复用long数组(HeapMemoryAllocator)。TaskMemoryManager接管Task的内存分配释放，&amp;ldquo;寻址&amp;rdquo;，分配的内存页大小不固定，具体执行内存申请是由HeapMemoryAllocator和UnsafeMemoryAllocator进行。
Flink: MemoryManager接管内存分配和释放，构造时页的大小固定，页表大小根据需要的内存反推。TaskManagerServices构造MemoryManager时会将页大小定为networkBufferSize, 默认大小为32KB, 为了配合flink的Network Buffer管理。AbstractPagedInputView, AbstractPagedOutputView以及各种InputView OutputView 用来进行跨page读写内存。
这些缓解了GC耗时和抖动问题。
spill到内存外持久化存储 具体原理和为什么都不叫显然，两者实现也没有什么差别。
Flink: 由内存使用者管理spill规则，并不像操作系统一样。比如: MutableHashTable，SpillingBuffer&amp;hellip; Spark: 同样由各类使用者各自管理，所有内存的消费者都继承MemoryConsumer abstract class， 实现具体spill方法。相对Flink更整洁，统一。BytesToBytesMap，ExternalAppendOnlyMap，ExternalSorter会spill到disk。 列方式存储 根据空间局部性原理，做到缓存友好首先对数据进行向量化存储。通常我们都是对结构化数据的一&amp;quot;列&amp;quot;进行相同的处理，所以
缓存友好算法 codegen (SIMD AVX)</description></item><item><title>如何选择三种Spark API</title><link>https://example.com/posts/spark_api/</link><pubDate>Fri, 11 Nov 2016 14:30:27 +0800</pubDate><guid>https://example.com/posts/spark_api/</guid><description>在这里查看 Apache Spark 2.0 Api 的改进：RDD，DataFrame，DataSet和SQL
Apache Spark 正在快速发展，包括更改和添加核心API。最具破坏性的改变之一是dataset。 Spark 1.0 使用RDD API，但是在最近的十二个月引入了两个新不兼容的API。Spark 1.3 引入了完全不同的DataFrame API 而且最近发布的 Spark 1.6 引入了 Dataset API 浏览版。
很多现有的 Spark 开发者想知道是否应该从 RDDs 直接切换到 Dataset API，或者先切换到 DataFrame API。Spark 新手应该选择哪个 API 开始学习。
这篇文章将提供每个API的概述，并且总结了每个的优缺点。 配套的github repo提供了例子，可以从这开始实验文中提到的方法。yd
RDD (弹性分布式数据集) API 从 1.0 开始一直存在 Spark 中。 这个接口和 Java 版本 JavaRDD 对于已经完成标准Spark教程的任何开发人员来说都是熟悉的。从开发人员的角度来看，RDD只是一组表示数据的Java或Scala对象。
RDD API 提供很多转换方法来在数据上执行计算，比如 map() ， filter() ，和 reduce() 。这些方法的结果表示转换后的新RDD。 然而，这些方法只是定义要执行的操作，直到调用action方法才执行转换。action 方法比如是： collect() 和 saveAsObjectFile().
RDD 转换和action例子 Scala: rdd.</description></item></channel></rss>